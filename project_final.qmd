---
title: "PROJECT"
subtitle: "BLAL BLA BLA"
author: anonymous
format:
  html:
    toc: true
    code-tools: true
    code-line-numbers: true
    msainfont: Georgia, serif
    page-layout: article
  pdf:  
    number-sections: true
    code-annotations: none
editor: source
---

::: {.content-hidden when-format="pdf"}
::: {.callout-warning collapse="false"}
## Setup

Install packages:

```{r}
#| label: Setup
remotes::install_github("higgi13425/medicaldata")
library(medicaldata)
library(dplyr)
library(brms)
library(corrplot)
library(rstanarm)
library(ggplot2)
library(loo)
library(rstanarm)
library(caret)
library(splines)
library(MASS)
# library(RColorBrewer)
library(gridExtra)
library(grid)
seed = 1234
```

Import the data:

```{r}
#| label: Importing-data
cath <- medicaldata::cath
```
:::
:::

# Introduction

-   Background
-   Problem formulation/scope
-   Main modeling idea
-   Some picture of the data?

# Data Desctription

The "cath" dataset used in this report is obtained from Duke University Cardiovascular Disease Databank. It encapsulates a collection of 6 variables (@Data-table) that are closely related to cardiovascular health.

```{r}
#| label: Data-table
#| echo: false
#| message: false
#| warning: false
#| tbl-cap: TBD
knitr::kable(head(cath))
```

The dataset consists of four explanatory variables (*sex*, *age*, *cad_dur*, *choleste*) and two response variables (*sigdz*, *tvdlm*) that provide an overview on patient demographics, clinical indicators, and critical outcomes related to coronary artery disease:

-   **Sex** (*sex*): Categorized as 0 for male and 1 for female, this variable represents the gender distribution within our dataset.

-   **Age** (*age*): Representing the age of patients in years, this variable serves as a demographic feature.

-   **Chest Pain Duration** (*cad_dur*): The duration of chest pain symptoms in days.

-   **Serum Cholesterol Level** (*choleste*): Measured in milligrams per deciliter, serum cholesterol levels are indicative of lipid metabolism and play a crucial role in cardiovascular health.

-   **Significant Coronary Disease** (*sigdz*): A binary variable that captures the presence (1) or absence (0) of at least 75% blockage in one of the major coronary arteries.

-   **Three Vessel Disease or Left Main Disease** (*tvdlm*): Denoting the presence (1) or absence (0) of blockage in either all three coronary vessels or in the left main coronary artery.

The univariate distributions of these variables are visualized in @Univariate-analysis.

```{r}
#| label: Univariate-analysis
#| echo: false
#| fig-cap: TBD 1

par(mfrow = c(2,3), oma = c(2,2,0.1,0.1)) # TBD

variable_names = names(cath)
colors = c("#F4CAE4", "#E6F5C9")

# Explanatory variables
barplot(table(cath[,1]), main = variable_names[1], 
  xlab = variable_names[1], col = colors[1])
for(i in 2:4){
  hist(cath[[i]], main = variable_names[i], 
    xlab = variable_names[i], col = colors[1])
}

# Response variables
for(i in 5:6){
  barplot(table(cath[,i]), main = variable_names[i], 
    xlab = variable_names[i], col = colors[2])
}
```

While constructing the Bayesian models to predict the probaility of significant coronary disease, the report strives to utilize the correlation between the explanatory variables (*sex*, *age*, *cad_dur*, *choleste*) and the desired response variable (*sigdz*). The *tvdlm* variable is not relevant in this report as the main focus is to predict the probability of significant coronary disease, independent of the type of the blockade.

```{r}
#| label: Data-preprocessing
#| echo: false
#| warning: false
#| message: false

# Remove tvdlm column
# Remove rows with at least one NA value
cath <- cath %>%
  na.omit() %>%
  dplyr::select(-tvdlm)

# Scale the variables
for (i in 1:(ncol(cath)-1)){
    cath[i] <- scale(cath[i])
}

# Dimensions after preprocessing
cath_dims <- dim(cath)
n_obs <- cath_dims[1]
```

Before the analysis, the data is preprocessed by removing *tvdlm* column and all rows that contain missing values, as well as by scaling the continuous variables to zero mean and unit variance. After this, we are left with $n =$ `r n_obs` observations. The pairwise correlations of variables are visualized in @Bivariate-analysis. We can see that variables *sex* and *age* have the most significant bivariate correlation to the responsive variable *sigdz*.

```{r}
#| label: Bivariate-analysis
#| echo: false
#| fig-cap: TBD 3

par(mfrow=c(1,1))
p <- ncol(cath)

corrplot(cor(cath[, c(p,1:(p-1))]), type = "full", method = "number")
```

# Mathematical Model

In this analysis, we will construct two models for inferring the binary response variable, *sigdz* based on input explanatory variables*.* The first model is a generalized linear model (GLM), namely Bayesian logistic regression. The other model is a generalized additive mixed model (GAMM), which implements Bayesian logistic regression with nonlinear transformations on the input variables. These models will be referred as linear and nonlinear model, respectively.

(((To-be-done still: - Check likelihood notation for nonlinear model - Prior justification - Check prior notations - Include priors with own values ? - **Posteriors** ?)))

## The generalized linear model and priors

Let $y$ be the number of times the variable *sigdz* is realized to be 1 for one individual in the dataset, and let $x$ be the explanatory variables for this outcome. Then, this number of successes for one individual follows a Binomial distribution

$$
y \sim \binom{n}{y}\theta^y(1-\theta)^{n-y},
$$

where n is the number of observations for that specific individual and $\theta = g^{-1}(\eta)$ $(\eta = \alpha + x^{T} \beta)$ is the probability of success (patient presenting with significant coronary disease). The inverse link function $g^{-1}$ maps the output of the linear predictor $\eta$ to a probability interval between 0 and 1.

For the binomial GLM, this project utilizes logit $g(x) = \ln(\frac{x}{1-x})$ as a link function, which makes it a logistic regression model. As each individual occurs only once in the data, $y$ can be directly presented as the binary response variable. Therefore, the likelihood of the response variable of one individual is reduced to Bernoulli distribution

$$
y \sim \text{ logit}^{-1}(\eta)^y(1-\text{ logit}^{-1}(\eta))^{1-y}.
$$

The complete data likelihood is then a product of $n =$ `r n_obs` likelihoods, with unshared probability of success.

As in Bayesian logistic regression the scope is to infer the distribution of the regression weights, namely the intercept $\alpha$ and coefficients $\beta = [\beta_1, \beta_2, \beta_3, \beta_4]^T$, we define the prior to be Student's $t$-distribution

$$
\begin{aligned} 
\alpha &\sim t_v(\mu, \sigma) \\ 
\beta_k &\sim t_v(\mu, \sigma), \ k=1,..,4 \\ 
\end{aligned} 
$$

where $v$ is the degrees of freedom, $\mu$ is the location and $\sigma$ is the scale.

The selection of prior distribution was done based on the nature of the data. Due to correlations, there is reason to believe that the parameters are not very close to zero, but most are still rather small than large. Therefore, as Student's $t$-distribution has heavy tails and larger scale compared to, for example, Gaussian distribution, $t$-distribution is a suitable choice of prior for this purpose. The parameters of the prior were defined to be

$$
v = 3, \quad \mu = 0, \quad \sigma = 2.5,
$$

as the coefficients can be positive or negative.

Finally, the joint posterior distribution that is simulated using Hamiltonian Monte Carlo (HMC) is proportional to the product of likelihood and prior distributions:

$$
p(\alpha, \beta | \bf{x}, \bf{y} ) \propto t_v(\alpha | \mu, \sigma) \times \prod^4_{k=1} t_v(\beta_k | \mu, \sigma) \times \prod^n_{i=1} \text{ logit}^{-1}(\eta_i)^{y_i}(1-\text{ logit}^{-1}(\eta_i))^{1-y_i}
$$

## The generalized additive nonlinear model

The additive nonlinear model on the other hand combines multiple functions in a way that is not strictly linear. This allows for a more flexible relationship between the explanatory variables and response variable $y$. In this report, the nonlinear model uses the same link function as the linear model, and so the nonlinear predictor for the logistic regression model can be written as:

$$
\text{logit} (\theta) = \eta = \alpha + \sum^4_{k=1} \beta_k f_k(x_k),
$$

where $f_k$ are nonlinear functions that transform the explanatory features individually. In this report, all functions of the continuous variables are smoothing functions. The $f_{age}$ is simply the variable itself, due to *sex* being binary variable. The smoothing functions utilize penalized splines, allowing the model to create a curved relationship between the features. The shape of the smoothing functions is estimated from the data and the penalty helps avoid overfitting. The smoothing function works by minimizing the sum of the model fit with the smoothness / penalty (here, thin plate regression splines (default)).

The likelihood of observation is the same as with the linear model, with the difference that a nonlinear transformation is applied to all input explanatory variables $\bf{x}$. Additionally, we utilize the same prior in both models to make them as comparable as possible. The posterior is again similar as with the linear model, but with the difference of nonlinear transformations on the input data.

# Model Definitions and Implementation

(((TO DO: - Explain in more detail what stan_glm and stan_gamm4 do - check if line 218 is necessary (x \<- model.matrix(sigdz \~ . - 1, data=cath)) IF NOT: --\> remove commented code)))

The linear and nonlinear models are implemented as Stan code with the rstanarm package as described below. Both models were implemented with identical number of chains, draws and warm-up. The default values (chains = 4, draws = 4000, and warmup = 2000) were used in both cases.

## Linear model

The linear model was implemented with the help of the `stan_glm` function from the rstanarm package. `stan_glm` is used to fit generalized linear models and performs a full Bayesian estimation with Markov Chain Monte Carlo (MCMC) estimation instead of maximum likelihood estimation and by adding priors to the GLM coefficients and intercept. By defining the model parameter `family = binomial(link = 'logit')` the model performs logistic regression.  

The linear relationship between the response variable `sigdz` and the explanatory variables are defined with the help of the `formula` function and the prior for the regression coefficients and intercept with the help of the `student_t` function.

```{r}
#| label: Linear-model-definition
#| warning: false
#| message: false

# Make response variable a factor
cath$sigdz <- as.factor(cath$sigdz)

#x <- model.matrix(sigdz ~ . - 1, data=cath)
y <- cath$sigdz

# Formula
formula_linear <- formula(sigdz ~ sex + age + cad_dur + choleste)

# Prior
prior_linear <- student_t(df = 3, location = 0, scale = 2.5)

# The model
model_linear <- stan_glm(formula_linear, data = cath,
                family = binomial(link = "logit"), 
                prior = prior_linear, prior_intercept = prior_linear,
                QR=TRUE, refresh=0)

# saveRDS(model_linear, file = "./additional_files/model_linear.rds")
# model_linear <- readRDS("./additional_files/model_linear.rds")                
```

## Nonlinear model

The nonlinear model is similarly implemented utilizing `stan_gamm4` function from the rstanarm package and defined to be a logistic regression model with the help of the model parameter `family = binomial(link = 'logit')`. `stan_gamm4` fits a generalized additive mixed model, and performs Bayesian MCMC estimation instead of maximum likelihood estimation. In the same way as `stan_glm`, the model adds independent priors to the regression coefficients and intercept.

The nonlinear relationship between the response variable `sigdz` and the explanatory variables is again defined with the help of the `formula` function. This time, passing the smoothing function `s()` for all continuous explanatory variables, to allow for more complexity in the model, while simultaneously penalizing over-fitting of the model with the the thin plate regression splines smoothness.

The same priors are used as for the linear model for both the intercept and the regression coefficients.

```{r}
#| label: Nonlinear model definition
#| warning: false
#| message: false

# Formula
formula_nonlinear <- formula(sigdz ~ sex + s(age) + s(cad_dur) + s(choleste))

# Model definition
model_nonlinear <- stan_gamm4(
  formula_nonlinear, data = cath,
  family = binomial(link = "logit"),
  prior = prior_linear, prior_intercept = prior_linear,
  refresh = 0
)

# saveRDS(model_nonlinear, file = "./additional_files/model_nonlinear.rds")
# model_nonlinear <- readRDS("./additional_files/model_nonlinear.rds")
```

# Model Evaluation

After fitting the models, multiple evaluation metrics such as split-$\hat{R}$, effective sample size (ESS) and number of divergent transitions were used to assess the convergence of MCMC chains separately for each model. Additionally, we perform posterior predictive checks, assess the model performances as well as compare the models utilizing leave-one-out cross validation (LOO-CV). Finally, we perform prior sensitivity analysis for both models.

-   Rhat, ESS, HMC divergences, pp_check(), loo_compare(), classification accuracy
-   Prior sensitivity analysis

## Convergence diagnostics & posterior predictive checks

For the linear model, the posterior predictive check and posterior distributions of the parameters with 95 % credible interval are visualized in @linear-model-plots. As we can see, the model fits the data relatively well, with a bit of a variation around the probability interval endpoints.

```{r}
#| label: linear-model-pp-check
#| fig-cap: TBD
#| echo: false

# posteriors
pplot_linear<-plot(model_linear, "areas", prob = 0.95, prob_outer = 1)
pplot_linear + geom_vline(xintercept = 0) +
labs(title="Posterior distributions of the linear model")
# pp check
pp_check_linear <- brms::pp_check(model_linear) +
labs(title="Posterior predictive check for the linear model")
grid.arrange(pplot_linear, pp_check_linear, ncol=2) 
```

The convergence diagnostics for the linear model are summarized below.

```{r}
#| label: Linear-model-convergence-diagnostics
#| echo: false

Rhat_linear <- model_linear$stan_summary[, "Rhat"] %>% round(3)
np_linear <- nuts_params(model_linear)
divergents_linear <- sum(subset(np_linear, Parameter == "divergent__")$Value)
ess_ratio_linear <- neff_ratio(model_linear)
sd_ess_ratio_linear <- sd(ess_ratio_linear) %>% round(3)

cat("Split-Rhat:\n")
print(Rhat_linear)
cat("Number of divergent transitions: ", divergents_linear, "\n")
cat("ESS ratio: \n")
print(ess_ratio_linear)
cat("Sd of ESS ratio: ", sd_ess_ratio_linear)
```

The HMC chains have converged, as all split-$\hat{R}$ values are below 0.01. Additionally, there were no divergent transitions during convergence, and thus the HMC simulation is reliable. The ratio of the ESS to the true sample size is over 1 with all explanatory variables as well as the intercept. Although high ESS is generally a good thing, this also implies the MCMC samples may have a negative correlation.

For the nonlinear model, the posterior predictive check is visualized in @nonlinear-model-pp-check. Based on visual inspection, the nonlinear model fits the data as well as the linear model. Like with the linear model, the posterior has a bit of a variation around the probability interval endpoints.

```{r}
#| label: nonlinear-model-pp-check
#| fig-cap: TBD
#| echo: false

# pp check
brms::pp_check(model_nonlinear) +
labs(title="Posterior predictive check for the nonlinear model")
```

The convergence diagnostics for the nonlinear model are summarized below.

```{r}
#| label: Nonlinear-model-Convergence-diagnostics
#| echo: true

Rhat_nonlinear <- model_nonlinear$stan_summary[, "Rhat"] %>% round(3)
np_nonlinear <- nuts_params(model_nonlinear)
divergents_nonlinear <- sum(subset(np_nonlinear, Parameter == "divergent__")$Value)
ess_ratio_nonlinear <- neff_ratio(model_nonlinear) %>% round(3)

rhat_satisfied_nonlinear <- all(Rhat_nonlinear <= 1.01)
mean_ess_ratio <- mean(ess_ratio_nonlinear) %>% round(3)
sd_ess_ratio_nonlinear <- sd(ess_ratio_nonlinear) %>% round(3)

cat("Split-Rhat of the first coefficients:\n")
print(head(Rhat_nonlinear))
cat("All split-Rhat <= 0.01: ", rhat_satisfied_nonlinear, "\n")
cat("Number of divergent transitions: ",divergents_nonlinear, "\n")
cat("ESS ratio of the first coefficients: \n")
print(head(ess_ratio_nonlinear))
cat("Mean of ESS ratio: ", mean_ess_ratio)
cat("Sd of ESS ratio: ", sd_ess_ratio_nonlinear)
```

Also the MCMC chains for this model have converged, as the split-$\hat{R}$ is less than 0.01 for all coefficients. As with the linear model, there were no divergent transitions during convergence, and thus the HMC simulation is reliable. On the other hand, the ESS ratio is on average less than 1, so a bit lower than with the linear model. However, the standard deviation of the ESS ratios is over twice larger than with the linear model. Low ESS ratio is not good in the model sense, but nevertheless the nonlinear has multiple coefficients to balance out the overall effect.

## Model comparison using LOO-CV

To compare the performance of the linear model and nonlinear model to each other as well as to a baseline model, we will compute the expected log-densities of the predictive distributions (ELPD) by applying Pareto smoothed LOO-CV (PSIS-LOO) to the models. The baseline model is simply a logistic regression model without any explanatory variables and with a unit coefficient.

```{r}
#| label: Baseline-model
# Baseline model
model_baseline <- update(model_linear, formula = sigdz ~ 1, QR = FALSE)
```

The results of the PSIS-LOO for each model are presented below.

```{r}
#| label: Computing-LOOs
#| echo: false
#| warnings: false
# LOO of our models
loo_linear <- loo(model_linear, save_psis = TRUE)
loo_nonlinear <- loo(model_nonlinear, save_psis = TRUE)
# LOO of the baseline model
loo_baseline <- loo(model_baseline, save_psis = TRUE)
```

```{r}
#| label: Printing-LOOs
#| echo: false
print("Linear model:")
print(loo_linear)
print("Nonlinear model:")
print(loo_nonlinear)
print("Baseline model:")
print(loo_baseline)
```

For each model, all Pareto k estimates are < 0.5, which implies the importance sampling gives a reliable estimate on the computed ELPDs. Additionally, for linear and nonlinear model the p_loo is less than the number of parameters in the respective model, and thus the model specifications seem to be reasonable. 

To assess the model ELPDs with respect to each other, we compute the comparison between the results of PSIS-LOO:

```{r}
#| label: Comparing LOOs
#| echo: false
loo_compare(loo_linear, loo_nonlinear, loo_baseline)
```

It indeed seems that the predictive performances of both linear and nonlinear models are better compared to the baseline model. Additionally, the scale of the difference of standard errors (es_diff) of the baseline model and nonlinear model is smaller than the difference of the ELPDs of the nonlinear and baseline model, which implies the difference in predictive log-densities between these models is not simply explained by the variance. Although the difference in ELPDs of the linear and nonlinear models is small, the nonlinear model slightly outperforms the linear model.

## Posterior predictive performance: Classification accuracy

To estimate the generalization error, i.e. the eneralization and performance of models on unseen data, we compute LOO-balanced classification accuracies for the linear and nonlinear models.

### Linear model:

```{r}
#| label: Linear model - Predictive probs
## Predicted probabilities
# linpred_linear <- posterior_linpred(model_linear)
preds_linear <- posterior_epred(model_linear)
pred_linear <- colMeans(preds_linear)
# pr_linear <- as.integer(pred_linear >= 0.5)
   
## posterior classification accuracy
# round(mean(xor(pr_linear,as.integer(y==0))),2)

# # posterior balanced classification accuracy
# round((mean(xor(pr_linear[y==0]>0.5,as.integer(y[y==0])))+mean(xor(pr_linear[y==1]<0.5,as.integer(y[y==1]))))/2,2)
```

```{r}
#| label: Linear model - LOO balanced predictive probs
# LOO predictive probabilities
ploo_linear=E_loo(preds_linear, loo_linear$psis_object, type="mean", log_ratios = -log_lik(model_linear))$value
ploo_linear
# LOO classification accuracy
round(mean(xor(ploo_linear>0.5,as.integer(y==0))),2)

# LOO balanced classification accuracy
round((mean(xor(ploo_linear[y==0]>0.5,as.integer(y[y==0])))+mean(xor(ploo_linear[y==1]<0.5,as.integer(y[y==1]))))/2,2)
```

### Nonlinear model

```{r}
#| label: Nonlinear model - Predictive probs
## Predicted probabilities
linpred_nonlinear <- posterior_linpred(model_nonlinear)
preds_nonlinear <- posterior_epred(model_nonlinear)
pred_nonlinear <- colMeans(preds_nonlinear)
pr_nonlinear <- as.integer(pred_nonlinear >= 0.5)
   
## posterior classification accuracy
# round(mean(xor(pr_nonlinear,as.integer(y==0))),2)

# # posterior balanced classification accuracy
# round((mean(xor(pr_nonlinear[y==0]>0.5,as.integer(y[y==0])))+mean(xor(pr_nonlinear[y==1]<0.5,as.integer(y[y==1]))))/2,2)
```

LOO balanced (Better estimate, maybe let's include only these?):

```{r}
#| label: Nonlinear model - LOO balanced predictive probs
# LOO predictive probabilities
ploo_nonlinear=E_loo(preds_nonlinear, loo_nonlinear$psis_object, type="mean", log_ratios = -log_lik(model_nonlinear))$value

# LOO classification accuracy
round(mean(xor(ploo_nonlinear>0.5,as.integer(y==0))),2)

# LOO balanced classification accuracy
round((mean(xor(ploo_nonlinear[y==0]>0.5,as.integer(y[y==0])))+mean(xor(ploo_nonlinear[y==1]<0.5,as.integer(y[y==1]))))/2,2)
```

### Calibration curves

```{r}
#| label: Calibration plots
#| fig-cap: TBD X
cplot_linear <- ggplot(data = data.frame(pred=pred_linear,loopred=ploo_linear,
  y=as.numeric(y)-1), aes(x=loopred, y=y)) +
  stat_smooth(method='glm', formula = y ~ ns(x, 5), fullrange=TRUE, color="deeppink") +
  geom_abline(linetype = 'dashed') +
  labs(x = "Predicted (LOO)",y = "Observed",title = "Linear model - Calibration plot") +
  geom_jitter(height=0.02, width=0, alpha=0.05) +
  scale_y_continuous(breaks=seq(0,1,by=0.1)) +
  xlim(c(0,1)) +
  theme_minimal()

cplot_nonlinear <- ggplot(data = data.frame(loopred=ploo_nonlinear,
  y=as.numeric(y)-1), aes(x=loopred, y=y)) + 
  stat_smooth(method='glm', formula = y ~ ns(x, 5), fullrange=TRUE, color="deeppink") +
  geom_abline(linetype = 'dashed') + 
  labs(x = "Predicted (LOO)",y = "Observed",title = "Nonlinear model - Calibration plot") +
  geom_jitter(height=0.02, width=0, alpha=0.05) + 
  scale_y_continuous(breaks=seq(0,1,by=0.1)) + 
  xlim(c(0,1)) +
  theme_minimal() 

grid.arrange(cplot_linear, cplot_nonlinear, ncol=2)
```

## Prior sensitivity analysis

# Discussion

-   Problems, potential improvements?
-   Conclusion of analysis

# Lessons Learned

# References
